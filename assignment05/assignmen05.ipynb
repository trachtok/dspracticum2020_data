{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignmen05.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNx6r/dYDpi+vBI/QOpVpXe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trachtok/dspracticum2020_data/blob/main/assignment05/assignmen05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUNrMF9opFU7"
      },
      "source": [
        "# Transfer learning for classification\n",
        "*Kája Trachtová, Michaela Kecskésová, Martin Špilar, Dagmar Al Tukmachi*\n",
        "\n",
        "+ goal of this assignment is to take already trained classification model (MobileNetV2) and use it to classify our images\n",
        "+ there will be 2 classes: Superman vs Batman images\n",
        "\n",
        "### Workflow of this notebook\n",
        "1. Load libraries\n",
        "2. Prepare input data (split images into training and validation set)\n",
        "3. Download MobileNetV2 model\n",
        "4. Transfer learning - train MobileNetV2 for our classification\n",
        "5. Export model to TSjs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4Thlq97pLQE"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzpizA9wpFiz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from google.colab import drive\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHqfhUWgmZR6",
        "outputId": "6bd24614-f27a-4c0a-94b2-a64e78416fe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install split-folders\n",
        "import splitfolders"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEStg9RQpR67"
      },
      "source": [
        "## Prepare input data\n",
        "\n",
        "+ Mount Google Discs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSvyojdr-xAl",
        "outputId": "66efa363-f2b9-4f45-aefd-a39953baad0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7duj1bBpgzo"
      },
      "source": [
        "+ check what data we have, how many images in each class?\n",
        "+ why there is not the same number of images in each class? **because during model training, accuracy was not high enough so we went through misclassified images and tried to manually delete the most obvious ones (like images where both Batman and Superman were present) -> this helped to increase accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHvTSf-FoMzz",
        "outputId": "66fbf5d2-4abd-4b20-cd68-fa21d5eb00a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/assignment05_data/batman' | wc -l\n",
        "!ls '/content/drive/My Drive/assignment05_data/superman' | wc -l"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-KMmofupzO3"
      },
      "source": [
        "+ for effective usage of `ImageDataGenerator()` it would be better to have 2 folders: training and validation and in both a specific subset of images for classes batman & superman\n",
        "+ to obtain such order, we can use package `splitfolders`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kteJZnhnqHqN",
        "outputId": "87982d04-2fdb-41ac-f08b-84bfdaa301ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "splitfolders.ratio(\"/content/drive/My Drive/assignment05_data\", output=\"/content/drive/My Drive/assignment05_data/prepared_data\", seed=1337, ratio=(.8, .2)) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 549 files [00:08, 63.46 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_btiT1Sqt4P",
        "outputId": "87474a8c-c335-44f3-fc14-92acfa9e58d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/assignment05_data/prepared_data/train\"\n",
        "!ls \"/content/drive/My Drive/assignment05_data/prepared_data/val\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batman\tsuperman\n",
            "batman\tsuperman\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvtHx2YtszUp"
      },
      "source": [
        "train_dir = \"/content/drive/My Drive/assignment05_data/prepared_data/train\"\n",
        "validation_dir = \"/content/drive/My Drive/assignment05_data/prepared_data/val\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssnB-innGKsk"
      },
      "source": [
        "# Download MobileNetV2\n",
        "+ download MobileNetV2 model without the top layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYiOFj_Lq6k8"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "IMG_SIZE = (160, 160)\n",
        "IMG_SHAPE = IMG_SIZE + (3,)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da-ZD6LQGOe7"
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "# base_model.summary()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cz_0D2jGb-S"
      },
      "source": [
        "# Transfer learning\n",
        "+ using already trained model, first freeze all layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2RP5aXVGbXF"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_PbCOJirdDy"
      },
      "source": [
        "+ then add pooling layer and dropout, finally put on top `softmax` for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOK4su6DraJb"
      },
      "source": [
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(units=2, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGFRhLqKrwWN"
      },
      "source": [
        "+ create `ImageDataGenerator()` instance separately for training a validation set\n",
        "+ for training dataset, we can set several data augmentation parameters such as rotation, horizontal flip etc. -> it is not generally advised to do the same also for validation dataset, therefore, for validation only neccessary rescaling is set\n",
        "+ we tried to use several data augmentation parameters, but it only worsened the accuracy of prediction, this might be due to the fact that we do not have enough images to begin with and transforming them only confuses the model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sm2P0VJGiGG"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    rescale=1./255,\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4CPAHwpsgfa"
      },
      "source": [
        "+ create iterator through training and validation dataset with `.flow_from_directory()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jTJ1UkLGkb4",
        "outputId": "6696ce35-7537-4d19-dbe4-81c0d363f84d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle = True)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical', \n",
        "    shuffle=True)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 435 images belonging to 2 classes.\n",
            "Found 110 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV-7e9fDIUEF",
        "outputId": "ce89c5ff-4e68-47f7-9eb3-8391a4c7335c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_generator)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " 7/14 [==============>...............] - ETA: 6s - loss: 0.9166 - accuracy: 0.5580"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 19s 1s/step - loss: 0.8301 - accuracy: 0.5862 - val_loss: 0.5701 - val_accuracy: 0.7000\n",
            "Epoch 2/5\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.4638 - accuracy: 0.7655 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 3/5\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.3213 - accuracy: 0.8644 - val_loss: 0.3805 - val_accuracy: 0.8455\n",
            "Epoch 4/5\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.2753 - accuracy: 0.8805 - val_loss: 0.3603 - val_accuracy: 0.8455\n",
            "Epoch 5/5\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.2432 - accuracy: 0.9011 - val_loss: 0.3398 - val_accuracy: 0.8727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJh_0dAVu3y-"
      },
      "source": [
        "# Export to TSjs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pim4RCMpu8eJ",
        "outputId": "d9d11e63-fd52-4f3c-db32-d93e816c05c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/c8/c52e21c49b3baf0845e395241046a993e244dd4b94c9827a8cd2d9b18927/tensorflowjs-2.7.0-py3-none-any.whl (62kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 20kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: h5py<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.10.0)\n",
            "Collecting tensorflow-hub<0.10,>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/83/a7df82744a794107641dad1decaad017d82e25f0e1f761ac9204829eef96/tensorflow_hub-0.9.0-py2.py3-none-any.whl (103kB)\n",
            "\r\u001b[K     |███▏                            | 10kB 24.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 20kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 30kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 40kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 51kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 61kB 19.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 71kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 81kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 102kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.33.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.18.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.35.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow<3,>=2.1.0->tensorflowjs) (50.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.0)\n",
            "Installing collected packages: tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: tensorflow-hub 0.10.0\n",
            "    Uninstalling tensorflow-hub-0.10.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.10.0\n",
            "Successfully installed tensorflow-hub-0.9.0 tensorflowjs-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfhtvH0ku9SS",
        "outputId": "f722d456-a230-4b84-b70b-e1a21aae66db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflowjs as tfjs\n",
        "tfjs.converters.save_keras_model(model, \"/content/drive/My Drive/assignment05_data/export_model\")"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/keras_h5_conversion.py:123: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  return h5py.File(h5file)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWKk6c3fvP-v",
        "outputId": "4da42e79-ab34-402b-feef-e2fcf6e786ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"export_model\", 'zip', \"/content/drive/My Drive/assignment05_data/export_model/\", )\n",
        "\n",
        "from google.colab import files\n",
        "files.download('export_model.zip')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9eb2477d-b0b8-4632-9d49-44c81abcc171\", \"export_model.zip\", 8418057)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}